#!/usr/bin/env bash
# pkg - CRUX-like source-based package builder/manager
# License: MIT
#
# v0.4.0 additions:
# - Transactional upgrade (staging + swap with rollback on failure)
# - repo-list: list all ports (from all ports roots)
# - search: query ports index; shows checkmark for installed
# - path: print resolved port directory path
# - depends: recursive dependency listing with installed checkmarks
# - cache: rebuild ports index cache to accelerate search/list
# - quickdep: show direct depends/makedepends (no recursion)
#
set -Eeuo pipefail
IFS=$'\n\t'

PKG_VERSION="0.4.0"

: "${PKGROOT:=/}"
: "${PKGSTATE:=${PKGROOT%/}/var/lib/pkg}"
: "${PKGCACHE:=${PKGSTATE}/cache}"
: "${SOURCES_DIR:=${PKGCACHE}/sources}"
: "${BUILDS_DIR:=${PKGCACHE}/build}"
: "${BIN_DIR:=${PKGCACHE}/bin}"
: "${LOG_DIR:=${PKGSTATE}/logs}"
: "${INSTALLED_DIR:=${PKGSTATE}/installed}"
: "${REPOS_DIR:=${PKGSTATE}/repos}"
: "${REPOS_CONF:=${PKGSTATE}/repos.conf}"
: "${INDEX_FILE:=${PKGCACHE}/ports.index.tsv}"
: "${STAGING_DIR:=${PKGSTATE}/staging}"
: "${PORTS_DIRS:=}"

default_ports_dirs() {
  if [[ -d "./ports" ]]; then echo "./ports"; else echo "/usr/ports"; fi
  echo "$REPOS_DIR"
}

DRY_RUN=0
VERBOSE=0
KEEP_WORK=0
FORCE=0
FORCE_REMOVE=0
REBUILD=0
JOBS="${JOBS:-$(getconf _NPROCESSORS_ONLN 2>/dev/null || echo 1)}"

die() { echo "pkg: error: $*" >&2; exit 1; }
warn(){ echo "pkg: warning: $*" >&2; }
info(){ echo "pkg: $*"; }
vinfo(){ ((VERBOSE)) && info "$@"; }
run() { if ((DRY_RUN)); then echo "+ $*"; else ((VERBOSE)) && echo "+ $*"; "$@"; fi; }
need_cmd() { command -v "$1" >/dev/null 2>&1 || die "missing dependency: $1"; }
mkd() { local p; for p in "$@"; do [[ -n "$p" ]] && run mkdir -p "$p"; done; }
as_root_needed() { if [[ "${PKGROOT}" == "/" ]]; then [[ "$(id -u)" -eq 0 ]] || die "requires root (or set PKGROOT)"; fi; }
trap_err() { local ec=$?; echo "pkg: failed (exit code $ec)" >&2; exit "$ec"; }
trap trap_err ERR

usage() {
  cat <<'EOF'
pkg - CRUX-like source-based package builder/manager

Global options:
  --root <path>
  --ports <p1[:p2...]>
  --dry-run
  --verbose
  --keep-work
  --force
  --rebuild
  --force-remove
  -j, --jobs <n>

Commands:
  repo list|add|remove|update
  repo-list                 List all ports available in configured roots (uses cache if present)
  cache                     Rebuild ports cache/index for fast queries
  search <term>             Search ports; shows ✔ for installed
  path <pkg>                Show physical port directory path
  quickdep <pkg|portdir>    Show direct depends/makedepends (no recursion)
  depends <pkg|portdir>     Show recursive dependencies; ✔ for installed
  fetch <pkg|portdir>
  build <pkg|portdir>
  install <name> [--from <pkg|portdir>]
  remove <name>
  upgrade <name|all>        Transactional upgrade (staging then swap)
  list
  info <name>
  clean <name> | clean --all
  gc
EOF
}

version() { echo "pkg ${PKG_VERSION}"; }

while [[ $# -gt 0 ]]; do
  case "$1" in
    --root) PKGROOT="$2"; shift 2 ;;
    --ports) PORTS_DIRS="$2"; shift 2 ;;
    --dry-run) DRY_RUN=1; shift ;;
    --verbose) VERBOSE=1; shift ;;
    --keep-work) KEEP_WORK=1; shift ;;
    --force) FORCE=1; shift ;;
    --rebuild) REBUILD=1; shift ;;
    --force-remove) FORCE_REMOVE=1; shift ;;
    -j|--jobs) JOBS="$2"; shift 2 ;;
    -h|--help) usage; exit 0 ;;
    -V|--version) version; exit 0 ;;
    --) shift; break ;;
    *) break ;;
  esac
done

cmd="${1:-}"; shift || true
PKGROOT="${PKGROOT%/}"; [[ -z "$PKGROOT" ]] && PKGROOT="/"

init_layout() {
  mkd "$PKGSTATE" "$PKGCACHE" "$SOURCES_DIR" "$BUILDS_DIR" "$BIN_DIR" "$LOG_DIR" "$INSTALLED_DIR" "$REPOS_DIR" "$STAGING_DIR"
  if [[ ! -f "$REPOS_CONF" && $DRY_RUN -eq 0 ]]; then : >"$REPOS_CONF"; fi
}

start_logging() {
  local ts; ts="$(date -u +"%Y%m%dT%H%M%SZ")"
  local lf="${LOG_DIR}/pkg-${ts}-$$.log"
  if ((DRY_RUN)); then echo "+ (logging would go to $lf)"; return 0; fi
  exec > >(tee -a "$lf") 2>&1
  info "logfile: $lf"
}

get_ports_roots() {
  local roots=()
  if [[ -n "$PORTS_DIRS" ]]; then
    IFS=':' read -r -a roots <<<"$PORTS_DIRS"
  else
    while IFS= read -r p; do roots+=("$p"); done < <(default_ports_dirs)
  fi
  local out=() seen="" r
  for r in "${roots[@]}"; do
    [[ -z "$r" ]] && continue
    r="${r%/}"
    [[ -d "$r" ]] || continue
    if [[ ":$seen:" != *":$r:"* ]]; then out+=("$r"); seen="${seen}:$r"; fi
  done
  printf '%s\n' "${out[@]}"
}

is_portdir() { [[ -d "$1" && -f "$1/Pkgfile" ]]; }

resolve_portdir() {
  local ref="$1"
  if is_portdir "$ref"; then echo "$ref"; return 0; fi
  local name="$ref" root
  while IFS= read -r root; do
    [[ -z "$root" ]] && continue
    local found
    found="$(find "$root" -maxdepth 2 -mindepth 2 -type f -name Pkgfile -path "*/${name}/Pkgfile" 2>/dev/null | head -n 1 || true)"
    [[ -n "$found" ]] && { echo "$(dirname "$found")"; return 0; }
    found="$(find "$root" -maxdepth 1 -mindepth 1 -type f -name Pkgfile -path "*/${name}/Pkgfile" 2>/dev/null | head -n 1 || true)"
    [[ -n "$found" ]] && { echo "$(dirname "$found")"; return 0; }
  done < <(get_ports_roots)
  die "could not resolve port '$name'"
}

# ---------------- Repo management ----------------
repo_list() { [[ -s "$REPOS_CONF" ]] && cat "$REPOS_CONF" || echo "(no repos configured)"; }

repo_add() {
  local name="$1" type="$2" url="$3" ref="${4:-}"
  [[ -n "$name" && -n "$type" && -n "$url" ]] || die "usage: pkg repo add <name> git <url> [ref] | rsync <src>"
  [[ "$type" == "git" || "$type" == "rsync" ]] || die "repo type must be git or rsync"
  if ((DRY_RUN)); then
    echo "+ update $REPOS_CONF: $name $type $url $ref"
  else
    tmp="$(mktemp)"
    awk -v n="$name" '$1!=n{print}' "$REPOS_CONF" >"$tmp" || true
    mv -f "$tmp" "$REPOS_CONF"
    printf '%s\t%s\t%s\t%s\n' "$name" "$type" "$url" "$ref" >>"$REPOS_CONF"
  fi
  info "repo added: $name"
}

repo_remove() {
  local name="$1"; [[ -n "$name" ]] || die "usage: pkg repo remove <name>"
  if ((DRY_RUN)); then
    echo "+ remove $name from $REPOS_CONF and delete $REPOS_DIR/$name"
  else
    tmp="$(mktemp)"
    awk -v n="$name" '$1!=n{print}' "$REPOS_CONF" >"$tmp" || true
    mv -f "$tmp" "$REPOS_CONF"
    rm -rf "${REPOS_DIR:?}/$name" || true
  fi
  info "repo removed: $name"
}

repo_update_one() {
  local name="$1" type="$2" url="$3" ref="$4" dest="${REPOS_DIR}/${name}"
  if [[ "$type" == "git" ]]; then
    need_cmd git
    if [[ -d "$dest/.git" ]]; then
      info "repo update (git): $name"
      run git -C "$dest" fetch --prune --tags
      [[ -n "$ref" ]] && run git -C "$dest" checkout --quiet "$ref"
      run git -C "$dest" pull --ff-only || true
    else
      info "repo clone (git): $name"
      if ((DRY_RUN)); then echo "+ rm -rf \"$dest\" && git clone \"$url\" \"$dest\""
      else rm -rf "$dest" || true; git clone "$url" "$dest"; fi
      [[ -n "$ref" ]] && run git -C "$dest" checkout --quiet "$ref"
    fi
  elif [[ "$type" == "rsync" ]]; then
    need_cmd rsync
    info "repo sync (rsync): $name"
    mkd "$dest"
    run rsync -a --delete "$url"/ "$dest"/
  else
    die "unknown repo type: $type"
  fi
}

repo_update() {
  local which="${1:-all}"
  [[ -f "$REPOS_CONF" ]] || die "repos config missing"
  [[ -s "$REPOS_CONF" ]] || { warn "no repos configured"; return 0; }
  local name type url ref
  while IFS=$'\t' read -r name type url ref; do
    [[ -z "$name" ]] && continue
    [[ "$which" != "all" && "$which" != "$name" ]] && continue
    repo_update_one "$name" "$type" "$url" "$ref"
  done <"$REPOS_CONF"
}

# ---------------- Recipe loading ----------------
read_recipe() {
  local portdir="$1" pkgfile="${portdir%/}/Pkgfile"
  [[ -f "$pkgfile" ]] || die "Pkgfile not found: $pkgfile"
  (
    set -Eeuo pipefail
    export LC_ALL=C
    export PATH="/usr/bin:/bin:/usr/sbin:/sbin:${PATH}"
    # shellcheck disable=SC1090
    source "$pkgfile"
    [[ -n "${name:-}" && -n "${version:-}" && -n "${release:-}" ]] || { echo "missing name/version/release" >&2; exit 3; }
    declare -F build >/dev/null || { echo "missing build()" >&2; exit 3; }
    printf '%s\0' "$name" "$version" "$release"
    printf '%s\0' "${source[@]:-}"; printf '\0'
    printf '%s\0' "${sha256sums[@]:-}"; printf '\0'
    printf '%s\0' "${depends[@]:-}"; printf '\0'
    printf '%s\0' "${makedepends[@]:-}"
  )
}

parse_recipe_stream() {
  mapfile -d '' -t _parts <"$1" || true
  [[ ${#_parts[@]} -ge 3 ]] || die "internal: invalid recipe stream"
  R_NAME="${_parts[0]}"; R_VERSION="${_parts[1]}"; R_RELEASE="${_parts[2]}"
  R_SOURCES=(); R_SUMS=(); R_DEPENDS=(); R_MAKEDEPENDS=()
  local i=3
  for ((; i<${#_parts[@]}; i++)); do [[ -z "${_parts[i]}" ]] && { ((i++)); break; }; R_SOURCES+=("${_parts[i]}"); done
  for ((; i<${#_parts[@]}; i++)); do [[ -z "${_parts[i]}" ]] && { ((i++)); break; }; R_SUMS+=("${_parts[i]}"); done
  for ((; i<${#_parts[@]}; i++)); do [[ -z "${_parts[i]}" ]] && { ((i++)); break; }; R_DEPENDS+=("${_parts[i]}"); done
  for ((; i<${#_parts[@]}; i++)); do [[ -z "${_parts[i]}" ]] && continue; R_MAKEDEPENDS+=("${_parts[i]}"); done
}

need_cmd sha256sum >/dev/null 2>&1 || true
hash_file_list() { need_cmd sha256sum; for f in "$@"; do [[ -f "$f" ]] && sha256sum "$f"; done | sha256sum | awk '{print $1}'; }

recipe_fingerprint() {
  local portdir="$1" pkgfile="${portdir%/}/Pkgfile" pdir="${portdir%/}/patches" fdir="${portdir%/}/files"
  local files=("$pkgfile")
  [[ -d "$pdir" ]] && while IFS= read -r p; do files+=("$p"); done < <(find "$pdir" -type f \( -name '*.patch' -o -name '*.diff' \) 2>/dev/null | sort || true)
  [[ -d "$fdir" ]] && while IFS= read -r p; do files+=("$p"); done < <(find "$fdir" -type f 2>/dev/null | sort || true)
  hash_file_list "${files[@]}"
}

# ---------------- Installed DB helpers ----------------
is_installed() { [[ -d "${INSTALLED_DIR}/$1" ]]; }
installed_version_release() {
  local meta="${INSTALLED_DIR}/${1}/meta"; [[ -f "$meta" ]] || return 1
  local v r
  v="$(awk -F= '$1=="version"{print $2}' "$meta" 2>/dev/null || true)"
  r="$(awk -F= '$1=="release"{print $2}' "$meta" 2>/dev/null || true)"
  [[ -n "$v" && -n "$r" ]] || return 1
  echo "${v}-${r}"
}

# ---------------- Ports index cache ----------------
rebuild_cache() {
  info "rebuilding ports cache: $INDEX_FILE"
  if ((DRY_RUN)); then
    echo "+ scan ports roots and write $INDEX_FILE"
    return 0
  fi
  mkd "$(dirname "$INDEX_FILE")"
  : >"$INDEX_FILE"
  local root pkgfile portdir name cat
  while IFS= read -r root; do
    [[ -z "$root" ]] && continue
    while IFS= read -r pkgfile; do
      portdir="$(dirname "$pkgfile")"
      name="$(basename "$portdir")"
      cat="$(basename "$(dirname "$portdir")")"
      # if port is directly under root, category equals name; normalize to "-"
      if [[ "$(dirname "$portdir")" == "$root" ]]; then cat="-"; fi
      printf '%s\t%s\t%s\n' "$name" "$cat" "$portdir" >>"$INDEX_FILE"
    done < <(find "$root" -type f -name Pkgfile 2>/dev/null | sort)
  done < <(get_ports_roots)
}

ensure_cache() {
  [[ -f "$INDEX_FILE" ]] || rebuild_cache
}

cmd_repo_list_ports() {
  ensure_cache
  if [[ ! -s "$INDEX_FILE" ]]; then
    echo "(no ports found)"
    return 0
  fi
  awk -F'\t' '{ if($2=="-") print $1; else print $2"/"$1 }' "$INDEX_FILE" | sort
}

cmd_search() {
  local term="${1:-}"; [[ -n "$term" ]] || die "usage: pkg search <term>"
  ensure_cache
  local line name cat path
  while IFS=$'\t' read -r name cat path; do
    [[ "$name" == *"$term"* || "$cat" == *"$term"* || "$path" == *"$term"* ]] || continue
    local mark=""
    if is_installed "$name"; then mark="✔"; fi
    if [[ "$cat" == "-" ]]; then
      printf '%s %s\n' "$name" "$mark"
    else
      printf '%s/%s %s\n' "$cat" "$name" "$mark"
    fi
  done <"$INDEX_FILE"
}

cmd_path() {
  local ref="${1:-}"; [[ -n "$ref" ]] || die "usage: pkg path <pkg>"
  echo "$(resolve_portdir "$ref")"
}

# ---------------- Dependency listing ----------------
quickdep_print() {
  local portdir="$1"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"
  echo "depends: ${R_DEPENDS[*]:-}"
  echo "makedepends: ${R_MAKEDEPENDS[*]:-}"
}

cmd_quickdep() {
  local ref="${1:-}"; [[ -n "$ref" ]] || die "usage: pkg quickdep <pkg|portdir>"
  local portdir; portdir="$(resolve_portdir "$ref")"
  quickdep_print "$portdir"
}

declare -A _dep_seen_list=()
dep_collect_recursive() {
  local ref="$1"
  local portdir; portdir="$(resolve_portdir "$ref")"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"

  local dep
  for dep in "${R_MAKEDEPENDS[@]}" "${R_DEPENDS[@]}"; do
    [[ -n "$dep" ]] || continue
    if [[ -n "${_dep_seen_list[$dep]:-}" ]]; then continue; fi
    _dep_seen_list["$dep"]=1
    echo "$dep"
    # recurse only if a port exists
    if resolve_portdir "$dep" >/dev/null 2>&1; then
      dep_collect_recursive "$dep" || true
    fi
  done
}

cmd_depends() {
  local ref="${1:-}"; [[ -n "$ref" ]] || die "usage: pkg depends <pkg|portdir>"
  _dep_seen_list=()
  local dep
  while IFS= read -r dep; do
    [[ -n "$dep" ]] || continue
    local mark=""
    if is_installed "$dep"; then mark="✔"; fi
    printf '%s %s\n' "$dep" "$mark"
  done < <(dep_collect_recursive "$ref" | awk 'NF' | sort -u)
}

# ---------------- Source handling ----------------
is_git_source() {
  local s="$1"
  [[ "$s" =~ ^git\+ || "$s" =~ ^git:// || "$s" =~ \.git($|[#@]) || "$s" =~ ^github: || "$s" =~ ^gitlab: ]] && return 0
  return 1
}

parse_git_ref() {
  local spec="$1" url ref=""
  [[ "$spec" =~ ^git\+ ]] && spec="${spec#git+}"
  if [[ "$spec" =~ ^github: ]]; then
    local rest="${spec#github:}" orgrepo="$rest"
    if [[ "$rest" == *"@"* ]]; then orgrepo="${rest%@*}"; ref="${rest#*@}"
    elif [[ "$rest" == *"#"* ]]; then orgrepo="${rest%#*}"; ref="${rest#*#}"; fi
    url="https://github.com/${orgrepo}.git"
  elif [[ "$spec" =~ ^gitlab: ]]; then
    local rest="${spec#gitlab:}" groupproj="$rest"
    if [[ "$rest" == *"@"* ]]; then groupproj="${rest%@*}"; ref="${rest#*@}"
    elif [[ "$rest" == *"#"* ]]; then groupproj="${rest%#*}"; ref="${rest#*#}"; fi
    url="https://gitlab.com/${groupproj}.git"
  else
    url="$spec"
    if [[ "$url" == *"@"* ]]; then ref="${url##*@}"; url="${url%@*}"
    elif [[ "$url" == *"#"* ]]; then ref="${url##*#}"; url="${url%#*#}"; fi
  fi
  echo "$url" "$ref"
}

fetch_http_ftp() {
  local url="$1" out="$2"
  [[ -f "$out" && $FORCE -eq 0 ]] && { vinfo "source cached: $(basename "$out")"; return 0; }
  if command -v curl >/dev/null 2>&1; then run curl -L --fail --retry 3 -o "$out.tmp" "$url"
  elif command -v wget >/dev/null 2>&1; then run wget -O "$out.tmp" "$url"
  else die "need curl or wget"; fi
  run mv -f "$out.tmp" "$out"
}

fetch_git() {
  need_cmd git
  local spec="$1" cachedir="$2"
  local parsed; parsed="$(parse_git_ref "$spec")"
  local url ref
  url="$(awk '{print $1}' <<<"$parsed")"; ref="$(awk '{print $2}' <<<"$parsed")"
  local base; base="$(basename "$url")"; [[ "$base" == *.git ]] || base="${base}.git"
  local mirror="${cachedir}/${base}"
  if [[ -d "$mirror" && $FORCE -eq 0 ]]; then
    vinfo "git cached: $base (updating mirror)"
    run git -C "$mirror" fetch --prune --tags || true
  else
    [[ -d "$mirror" && $FORCE -eq 1 ]] && run rm -rf "$mirror"
    info "cloning mirror: $url"
    run git clone --mirror "$url" "$mirror"
  fi
  if ((DRY_RUN)); then echo "+ echo \"$ref\" > \"$mirror/.pkg_ref\""
  else printf '%s' "$ref" >"$mirror/.pkg_ref"; fi
}

verify_sha256() {
  local file="$1" expected="$2"
  [[ -z "$expected" ]] && return 0
  need_cmd sha256sum
  local got; got="$(sha256sum "$file" | awk '{print $1}')"
  [[ "$got" == "$expected" ]] || die "sha256 mismatch for $(basename "$file")"
}

cmd_fetch() {
  local portdir; portdir="$(resolve_portdir "$1")"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"
  info "fetch: ${R_NAME} ${R_VERSION}-${R_RELEASE}"
  mkd "$SOURCES_DIR/${R_NAME}"
  local idx=0 spec
  for spec in "${R_SOURCES[@]}"; do
    [[ -z "$spec" ]] && continue
    if is_git_source "$spec"; then
      fetch_git "$spec" "$SOURCES_DIR/${R_NAME}"
    else
      local filename; filename="$(basename "${spec%%\?*}")"
      local out="${SOURCES_DIR}/${R_NAME}/${filename}"
      fetch_http_ftp "$spec" "$out"
      [[ ${#R_SUMS[@]} -gt 0 ]] && { [[ $idx -lt ${#R_SUMS[@]} ]] || die "sha256sums count mismatch"; verify_sha256 "$out" "${R_SUMS[$idx]}"; }
    fi
    ((idx++))
  done
}

# ---------------- Dependency installation (for build) ----------------
declare -A _dep_visiting=() _dep_visited=()

find_cached_pkg() {
  local name="$1"
  local f; f="$(ls -1 "${BIN_DIR}/${name}-"*.tar.gz 2>/dev/null | sort -V | tail -n 1 || true)"
  [[ -n "$f" ]] || return 1
  echo "$f"
}

resolve_and_install_deps() {
  local portdir; portdir="$(resolve_portdir "$1")"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"
  local dep
  for dep in "${R_MAKEDEPENDS[@]}" "${R_DEPENDS[@]}"; do [[ -n "$dep" ]] && install_dep_recursive "$dep"; done
}

install_dep_recursive() {
  local name="$1"
  [[ -n "${_dep_visited[$name]:-}" ]] && return 0
  [[ -n "${_dep_visiting[$name]:-}" ]] && die "dependency cycle detected at: $name"
  _dep_visiting["$name"]=1

  if is_installed "$name"; then
    vinfo "dep satisfied: $name"
  else
    if find_cached_pkg "$name" >/dev/null 2>&1; then
      as_root_needed
      cmd_install "$name"
    else
      local dep_portdir; dep_portdir="$(resolve_portdir "$name")"
      resolve_and_install_deps "$dep_portdir" || true
      cmd_build "$dep_portdir"
      as_root_needed
      cmd_install "$name" --from "$dep_portdir"
    fi
  fi

  unset _dep_visiting["$name"]
  _dep_visited["$name"]=1
}

# ---------------- Build & packaging ----------------
portable_tar() { local srcdir="$1" out="$2"; run tar -C "$srcdir" -czf "$out" .; }

unpack_source() {
  local file="$1" dest="$2"
  case "$file" in
    *.tar.gz|*.tgz) run tar -C "$dest" -xzf "$file" ;;
    *.tar.xz) run tar -C "$dest" -xJf "$file" ;;
    *.tar.bz2|*.tbz2) run tar -C "$dest" -xjf "$file" ;;
    *.tar.zst) need_cmd zstd; run tar -C "$dest" --use-compress-program=zstd -xf "$file" ;;
    *.tar) run tar -C "$dest" -xf "$file" ;;
    *.zip) need_cmd unzip; run unzip -q "$file" -d "$dest" ;;
    *) run cp -f "$file" "$dest/" ;;
  esac
}

checkout_git_mirror() {
  need_cmd git
  local mirror="$1" workdir="$2"
  local ref=""; [[ -f "$mirror/.pkg_ref" ]] && ref="$(cat "$mirror/.pkg_ref" || true)"
  local name; name="$(basename "$mirror" .git)"
  local out="${workdir}/${name}"
  [[ -d "$out" ]] && run rm -rf "$out"
  run git clone "$mirror" "$out"
  [[ -n "$ref" ]] && run git -C "$out" checkout --quiet "$ref"
}

apply_patches() {
  local portdir="$1" workdir="$2" pdir="${portdir%/}/patches"
  [[ -d "$pdir" ]] || return 0
  need_cmd patch
  shopt -s nullglob
  local patches=("$pdir"/*.patch "$pdir"/*.diff)
  shopt -u nullglob
  [[ ${#patches[@]} -eq 0 ]] && return 0
  info "applying patches from: $pdir"
  local p
  for p in "${patches[@]}"; do
    info "  patch: $(basename "$p")"
    if ((DRY_RUN)); then echo "+ (cd \"$workdir\" && patch -p1 < \"$p\")"
    else (cd "$workdir" && patch -p1 <"$p"); fi
  done
}

overlay_files() {
  local portdir="$1" destdir="$2" fdir="${portdir%/}/files"
  [[ -d "$fdir" ]] || return 0
  info "overlay files: $fdir -> DESTDIR"
  if ((DRY_RUN)); then echo "+ cp -a \"$fdir\"/. \"$destdir\"/"
  else cp -a "$fdir"/. "$destdir"/; fi
}

run_build() {
  local portdir="$1" workdir="$2" destdir="$3" buildlog="$4"
  (
    set -Eeuo pipefail
    export MAKEFLAGS="-j${JOBS}"
    export DESTDIR="$destdir"
    cd "$workdir"
    # shellcheck disable=SC1090
    source "$portdir/Pkgfile"
    build
  ) 2>&1 | tee -a "$buildlog"
}

cmd_build() {
  local portdir; portdir="$(resolve_portdir "$1")"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"
  resolve_and_install_deps "$portdir"

  local pkgid="${R_NAME}-${R_VERSION}-${R_RELEASE}"
  local out_pkg="${BIN_DIR}/${pkgid}.tar.gz"
  local out_meta="${BIN_DIR}/${pkgid}.meta"
  local fp; fp="$(recipe_fingerprint "$portdir")"

  if [[ -f "$out_pkg" && -f "$out_meta" && $REBUILD -eq 0 ]]; then
    local fp_old; fp_old="$(awk -F= '$1=="fingerprint"{print $2}' "$out_meta" 2>/dev/null || true)"
    [[ -n "$fp_old" && "$fp_old" == "$fp" ]] && { info "binary cache hit (fingerprint match): $(basename "$out_pkg")"; return 0; }
  fi

  mkd "$SOURCES_DIR/${R_NAME}" "$BUILDS_DIR/${pkgid}"
  local workbase="${BUILDS_DIR}/${pkgid}" workdir="${workbase}/work" destdir="${workbase}/dest"
  local buildlog="${LOG_DIR}/${pkgid}.build.log"
  [[ -d "$workbase" && ( $FORCE -eq 1 || $REBUILD -eq 1 ) ]] && run rm -rf "$workbase"
  mkd "$workdir" "$destdir"

  cmd_fetch "$portdir"

  local src_cache="${SOURCES_DIR}/${R_NAME}" spec
  for spec in "${R_SOURCES[@]}"; do
    [[ -z "$spec" ]] && continue
    if is_git_source "$spec"; then
      local parsed; parsed="$(parse_git_ref "$spec")"
      local url; url="$(awk '{print $1}' <<<"$parsed")"
      local base; base="$(basename "$url")"; [[ "$base" == *.git ]] || base="${base}.git"
      local mirror="${src_cache}/${base}"
      [[ -d "$mirror" ]] || die "missing git mirror: $mirror"
      checkout_git_mirror "$mirror" "$workdir"
    else
      local filename; filename="$(basename "${spec%%\?*}")"
      local f="${src_cache}/${filename}"
      [[ -f "$f" ]] || die "missing cached source: $f"
      unpack_source "$f" "$workdir"
    fi
  done

  apply_patches "$portdir" "$workdir"
  if ((DRY_RUN)); then echo "+ run build() in $workdir -> DESTDIR=$destdir"
  else : >"$buildlog"; fi
  run_build "$portdir" "$workdir" "$destdir" "$buildlog"
  overlay_files "$portdir" "$destdir"

  if ((DRY_RUN)); then
    echo "+ write metadata to $out_meta"
  else
    cat >"$out_meta" <<EOF
name=${R_NAME}
version=${R_VERSION}
release=${R_RELEASE}
built_at=$(date -u +"%Y-%m-%dT%H%M%SZ")
port_path=${portdir}
fingerprint=${fp}
EOF
  fi

  mkd "$BIN_DIR"
  portable_tar "$destdir" "$out_pkg"
  if ((KEEP_WORK==0)); then run rm -rf "$workbase"; fi
  info "built: $pkgid"
}

# ---------------- Install / transactional apply ----------------
record_files_and_hashes() {
  local name="$1" tarball="$2" dbdir="$3"
  need_cmd sha256sum
  if ((DRY_RUN)); then
    echo "+ tar -tzf \"$tarball\" > \"$dbdir/files\""
    echo "+ sha256 for installed files -> \"$dbdir/hashes\""
    return 0
  fi
  tar -tzf "$tarball" | sed 's#^\./##' >"$dbdir/files"
  : >"$dbdir/hashes"
  while IFS= read -r rel; do
    [[ -z "$rel" ]] && continue
    local p="${PKGROOT%/}/$rel"
    [[ -f "$p" && ! -L "$p" ]] && sha256sum "$p" >>"$dbdir/hashes" || true
  done <"$dbdir/files"
}

run_post_install_if_any() {
  local from_ref="$1" dbdir="$2"
  local portpath=""
  if [[ -n "$from_ref" ]]; then portpath="$(resolve_portdir "$from_ref")"
  else portpath="$(awk -F= '$1=="port_path"{print $2}' "$dbdir/meta" 2>/dev/null || true)"; fi
  if [[ -n "$portpath" && -f "$portpath/Pkgfile" ]]; then
    info "running post_install()"
    if ((DRY_RUN)); then
      echo "+ (source \"$portpath/Pkgfile\" && post_install)"
    else
      (
        set -Eeuo pipefail
        export PKGROOT="$PKGROOT"
        # shellcheck disable=SC1090
        source "$portpath/Pkgfile"
        declare -F post_install >/dev/null && post_install || true
      )
    fi
  fi
}

cmd_install() {
  local name="$1"; shift || true
  local from_ref=""
  while [[ $# -gt 0 ]]; do
    case "$1" in --from) from_ref="$2"; shift 2 ;; *) die "unknown install option: $1" ;; esac
  done

  local tarball
  if tarball="$(find_cached_pkg "$name")"; then :; else
    [[ -n "$from_ref" ]] || die "no cached binary for '$name' (use --from)"
    cmd_build "$from_ref"
    tarball="$(find_cached_pkg "$name")" || die "no cached binary after build for '$name'"
  fi

  as_root_needed
  local pkgid; pkgid="$(basename "$tarball" .tar.gz)"
  local dbdir="${INSTALLED_DIR}/${name}"
  [[ -d "$dbdir" && $FORCE -eq 0 ]] && die "already installed: $name"

  info "install: $pkgid -> $PKGROOT"
  mkd "$dbdir"
  if ((DRY_RUN)); then echo "+ write meta -> $dbdir/meta"
  else awk '1' "${BIN_DIR}/${pkgid}.meta" >"$dbdir/meta"; fi

  run tar -C "$PKGROOT" -xzf "$tarball"
  record_files_and_hashes "$name" "$tarball" "$dbdir"
  run_post_install_if_any "$from_ref" "$dbdir"
  info "installed: $name"
}

hash_lookup_expected() { awk -v p="$2" '$2==p{print $1; exit 0}' "$1" 2>/dev/null || true; }

remove_obsolete_files() {
  # remove files that were in old but not in new. Preserve modified unless --force-remove.
  local old_db="$1" new_list_file="$2"
  local old_files="$old_db/files" hashes="$old_db/hashes"
  [[ -f "$old_files" ]] || return 0
  local newtmp; newtmp="$(mktemp)"
  if ((DRY_RUN)); then
    echo "+ compute obsolete file set and remove"
    rm -f "$newtmp" || true
    return 0
  fi
  sort -u "$new_list_file" >"$newtmp"
  local rel
  while IFS= read -r rel; do
    [[ -z "$rel" ]] && continue
    grep -qxF "$rel" "$newtmp" && continue
    local p="${PKGROOT%/}/$rel"
    if [[ -f "$p" && ! -L "$p" && -f "$hashes" && $FORCE_REMOVE -eq 0 ]]; then
      local exp; exp="$(hash_lookup_expected "$hashes" "$p")"
      if [[ -n "$exp" ]]; then
        local got; got="$(sha256sum "$p" | awk '{print $1}' || true)"
        if [[ -n "$got" && "$got" != "$exp" ]]; then
          warn "preserving modified obsolete file: $p (use --force-remove to delete)"
          continue
        fi
      fi
    fi
    [[ -e "$p" || -L "$p" ]] && rm -f "$p" || true
  done < <(awk 'NF' "$old_files")
  rm -f "$newtmp"
}

transactional_apply_tarball() {
  # Staging + swap with rollback on failure.
  # Args: <name> <tarball> <new_meta_path> <old_db_dir_or_empty>
  need_cmd tar
  local name="$1" tarball="$2" meta_path="$3" old_db="${4:-}"
  local pkgid; pkgid="$(basename "$tarball" .tar.gz)"
  local stage="${STAGING_DIR}/${pkgid}"
  local root_stage="${stage}/root"
  local backup="${stage}/backup"
  local newlist="${stage}/new.files"

  info "transaction: staging to $root_stage"
  if ((DRY_RUN)); then
    echo "+ rm -rf \"$stage\"; mkdir -p \"$root_stage\" \"$backup\"; tar -C \"$root_stage\" -xzf \"$tarball\""
  else
    rm -rf "$stage" || true
    mkdir -p "$root_stage" "$backup"
    tar -C "$root_stage" -xzf "$tarball"
  fi

  # capture file list from tarball (canonical)
  if ((DRY_RUN)); then
    echo "+ tar -tzf \"$tarball\" > \"$newlist\""
  else
    tar -tzf "$tarball" | sed 's#^\./##' >"$newlist"
  fi

  # Rollback handler
  rollback() {
    warn "transaction failed; attempting rollback"
    if ((DRY_RUN)); then
      echo "+ (rollback would restore backups from $backup)"
      return 0
    fi
    if [[ -d "$backup" ]]; then
      # restore backed up files
      while IFS= read -r f; do
        [[ -z "$f" ]] && continue
        local src="${backup}/$f"
        local dst="${PKGROOT%/}/$f"
        [[ -e "$src" || -L "$src" ]] || continue
        mkdir -p "$(dirname "$dst")" || true
        rm -f "$dst" 2>/dev/null || true
        mv "$src" "$dst" 2>/dev/null || true
      done < <(find "$backup" -type f -o -type l 2>/dev/null | sed "s#^${backup}/##" | sort -r)
    fi
  }

  # Apply directories first
  if ((DRY_RUN)); then
    echo "+ create directories in $PKGROOT from staging"
  else
    while IFS= read -r d; do
      [[ -z "$d" ]] && continue
      mkdir -p "${PKGROOT%/}/$d" || true
    done < <(cd "$root_stage" && find . -type d | sed 's#^\./##' | awk 'NF' | sort)
  fi

  # Apply files and symlinks
  info "transaction: swapping files"
  if ((DRY_RUN)); then
    echo "+ for each staged file: backup existing then move into place"
    return 0
  fi

  local rel src dst
  while IFS= read -r rel; do
    [[ -z "$rel" ]] && continue
    src="${root_stage%/}/$rel"
    dst="${PKGROOT%/}/$rel"
    # if staging has directory, skip (handled)
    [[ -d "$src" ]] && continue
    mkdir -p "$(dirname "$dst")" || true
    if [[ -e "$dst" || -L "$dst" ]]; then
      mkdir -p "$(dirname "${backup}/$rel")" || true
      mv "$dst" "${backup}/$rel" 2>/dev/null || true
    fi
    # move in; if fails, rollback
    if ! mv "$src" "$dst" 2>/dev/null; then
      rollback
      die "transaction swap failed on: $rel"
    fi
  done <"$newlist"

  # Clean obsolete files from previous version
  if [[ -n "$old_db" && -d "$old_db" ]]; then
    info "transaction: removing obsolete files from previous version"
    remove_obsolete_files "$old_db" "$newlist"
  fi

  # success: remove staging (keep backup only for this run)
  rm -rf "$stage" 2>/dev/null || true
}

cmd_remove() {
  local name="$1"
  as_root_needed
  local dbdir="${INSTALLED_DIR}/${name}"
  [[ -d "$dbdir" ]] || die "not installed: $name"
  [[ -f "$dbdir/files" ]] || die "missing file list for $name"
  local hashes="${dbdir}/hashes"
  [[ -f "$hashes" ]] || warn "missing hashes for $name (will remove as listed)"
  info "remove: $name"

  local files; files="$(awk 'NF' "$dbdir/files" | sort -r)"
  local preserved=0 removed=0 rel
  while IFS= read -r rel; do
    [[ -z "$rel" ]] && continue
    local p="${PKGROOT%/}/$rel"
    if [[ -f "$p" && ! -L "$p" && -f "$hashes" && $FORCE_REMOVE -eq 0 ]]; then
      local exp; exp="$(hash_lookup_expected "$hashes" "$p")"
      if [[ -n "$exp" ]]; then
        local got; got="$(sha256sum "$p" | awk '{print $1}' || true)"
        if [[ -n "$got" && "$got" != "$exp" ]]; then
          warn "preserving modified file: $p (use --force-remove to delete)"
          preserved=$((preserved+1))
          continue
        fi
      fi
    fi
    if [[ -e "$p" || -L "$p" ]]; then run rm -f "$p" || true; removed=$((removed+1)); fi
  done <<<"$files"

  while IFS= read -r rel; do
    [[ -z "$rel" ]] && continue
    local d="${rel%/*}"; [[ "$d" == "$rel" ]] && continue
    local pd="${PKGROOT%/}/$d"
    [[ -d "$pd" ]] && run rmdir -p --ignore-fail-on-non-empty "$pd" 2>/dev/null || true
  done <<<"$files"

  run rm -rf "$dbdir"
  info "removed: $name (files removed: $removed, preserved: $preserved)"
}

cmd_list() { ls -1 "$INSTALLED_DIR" 2>/dev/null | sort || true; }

cmd_info() {
  local name="$1" dbdir="${INSTALLED_DIR}/${name}"
  [[ -d "$dbdir" ]] || die "not installed: $name"
  echo "Name: $name"
  [[ -f "$dbdir/meta" ]] && sed 's/^/  /' "$dbdir/meta"
  [[ -f "$dbdir/files" ]] && echo "Files: $(wc -l <"$dbdir/files" | tr -d ' ')"
}

cmd_clean_pkg() {
  local name="$1"
  run rm -rf "${BUILDS_DIR}/${name}-"* 2>/dev/null || true
  run rm -f "${BIN_DIR}/${name}-"*.tar.gz "${BIN_DIR}/${name}-"*.meta 2>/dev/null || true
  run rm -rf "${SOURCES_DIR:?}/${name}" 2>/dev/null || true
  info "cleaned caches for: $name"
}

cmd_clean_all() {
  info "clean --all: removing ALL caches and logs (does NOT uninstall)"
  run rm -rf "${BUILDS_DIR:?}/"* 2>/dev/null || true
  run rm -rf "${SOURCES_DIR:?}/"* 2>/dev/null || true
  run rm -rf "${BIN_DIR:?}/"* 2>/dev/null || true
  run rm -rf "${LOG_DIR:?}/"* 2>/dev/null || true
  run rm -rf "${STAGING_DIR:?}/"* 2>/dev/null || true
  info "done"
}

cmd_gc() {
  info "gc: removing temp files and empty dirs"
  run find "$SOURCES_DIR" -type f -name '*.tmp' -delete 2>/dev/null || true
  run find "$BUILDS_DIR" -mindepth 1 -maxdepth 1 -type d -empty -delete 2>/dev/null || true
  info "gc done"
}

# ---------------- Transactional upgrade ----------------
version_release_str() { echo "${1}-${2}"; }

cmd_upgrade_one() {
  local name="$1"
  is_installed "$name" || { warn "not installed: $name"; return 0; }
  local portdir; portdir="$(resolve_portdir "$name")"
  local tmp; tmp="$(mktemp)"; read_recipe "$portdir" >"$tmp"; parse_recipe_stream "$tmp"; rm -f "$tmp"
  local inst; inst="$(installed_version_release "$name" || echo "")"
  local target; target="$(version_release_str "$R_VERSION" "$R_RELEASE")"
  [[ -n "$inst" && "$inst" == "$target" ]] && { info "upgrade: $name is up-to-date (${inst})"; return 0; }

  info "upgrade: $name ${inst:-unknown} -> $target"
  cmd_build "$portdir"

  local tarball; tarball="$(find_cached_pkg "$name")" || die "no cached binary for '$name' after build"
  local pkgid; pkgid="$(basename "$tarball" .tar.gz)"
  local newmeta="${BIN_DIR}/${pkgid}.meta"
  local olddb="${INSTALLED_DIR}/${name}"

  # transactional apply
  transactional_apply_tarball "$name" "$tarball" "$newmeta" "$olddb"

  # update DB metadata + hashes and run post_install
  local dbdir="${INSTALLED_DIR}/${name}"
  if ((DRY_RUN)); then
    echo "+ update db meta/hashes for $name"
  else
    mkd "$dbdir"
    awk '1' "$newmeta" >"$dbdir/meta"
  fi
  record_files_and_hashes "$name" "$tarball" "$dbdir"
  run_post_install_if_any "$portdir" "$dbdir"
  info "upgraded: $name"
}

cmd_upgrade() {
  local which="${1:-all}"
  if [[ "$which" == "all" ]]; then
    local n
    while IFS= read -r n; do [[ -n "$n" ]] && cmd_upgrade_one "$n"; done < <(cmd_list)
  else
    cmd_upgrade_one "$which"
  fi
}

init_layout
start_logging

case "${cmd:-}" in
  repo)
    sub="${1:-}"; shift || true
    case "$sub" in
      list) [[ $# -eq 0 ]] || die "usage: pkg repo list"; repo_list ;;
      add) [[ $# -ge 3 ]] || die "usage: pkg repo add <name> git <url> [ref] | rsync <src>"; repo_add "$@" ;;
      remove) [[ $# -eq 1 ]] || die "usage: pkg repo remove <name>"; repo_remove "$1" ;;
      update)
        if [[ $# -eq 0 ]]; then repo_update "all"
        elif [[ $# -eq 1 ]]; then repo_update "$1"
        else die "usage: pkg repo update [name|all]"; fi
        ;;
      *) die "usage: pkg repo <list|add|remove|update>" ;;
    esac
    ;;
  cache) [[ $# -eq 0 ]] || die "usage: pkg cache"; rebuild_cache ;;
  repo-list) [[ $# -eq 0 ]] || die "usage: pkg repo-list"; cmd_repo_list_ports ;;
  search) [[ $# -eq 1 ]] || die "usage: pkg search <term>"; cmd_search "$1" ;;
  path) [[ $# -eq 1 ]] || die "usage: pkg path <pkg>"; cmd_path "$1" ;;
  quickdep) [[ $# -eq 1 ]] || die "usage: pkg quickdep <pkg|portdir>"; cmd_quickdep "$1" ;;
  depends) [[ $# -eq 1 ]] || die "usage: pkg depends <pkg|portdir>"; cmd_depends "$1" ;;
  fetch) [[ $# -eq 1 ]] || die "usage: pkg fetch <pkg|portdir>"; cmd_fetch "$1" ;;
  build) [[ $# -eq 1 ]] || die "usage: pkg build <pkg|portdir>"; cmd_build "$1" ;;
  install) [[ $# -ge 1 ]] || die "usage: pkg install <name> [--from <pkg|portdir>]"; cmd_install "$@" ;;
  remove) [[ $# -eq 1 ]] || die "usage: pkg remove <name>"; cmd_remove "$1" ;;
  upgrade) [[ $# -eq 1 ]] || die "usage: pkg upgrade <name|all>"; cmd_upgrade "$1" ;;
  list) [[ $# -eq 0 ]] || die "usage: pkg list"; cmd_list ;;
  info) [[ $# -eq 1 ]] || die "usage: pkg info <name>"; cmd_info "$1" ;;
  clean)
    if [[ $# -eq 1 && "$1" == "--all" ]]; then cmd_clean_all
    elif [[ $# -eq 1 ]]; then cmd_clean_pkg "$1"
    else die "usage: pkg clean <name> | pkg clean --all"; fi
    ;;
  gc) [[ $# -eq 0 ]] || die "usage: pkg gc"; cmd_gc ;;
  ""|-h|--help) usage ;;
  *) die "unknown command: ${cmd:-} (try --help)" ;;
esac
